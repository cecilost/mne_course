{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working in source space in MNE\n",
    "\n",
    "Localising activity in [source space](https://mne.tools/stable/documentation/glossary.html#term-source-space) is a fundamental part of many EEG and MEG analyses.\n",
    "\n",
    "Source space localisation generally involves:\n",
    "1. Computing a subject-specific [forward model](https://mne.tools/stable/documentation/glossary.html#term-forward-solution)\n",
    "2. Using the forward model to generate an [inverse model](https://mne.tools/stable/documentation/glossary.html#term-inverse-operator) for translating from sensor space to source space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Creating forward models\n",
    "\n",
    "Although MNE provides sample forward models, creating these based on MRI recordings of each individual subject offers greater accuracy when localising sources.\n",
    "\n",
    "Thankfully, MNE offers a number of tools for creating subject-specific forward models.\n",
    "\n",
    "Computing forward models requires:\n",
    "- [Coregistration information](https://mne.tools/stable/documentation/glossary.html#term-trans) (stored as a `-trans.fif` file) for aligning head and sensor positions\n",
    "- The boundary element model ([BEM](https://mne.tools/stable/documentation/glossary.html#term-BEM)) surfaces which influence how source activity propagates to the sensors\n",
    "- A source space of locations in the brain at which to estimate source activity\n",
    "\n",
    "We start by establishing the sample data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the sample data\n",
    "sample_data_path = mne.datasets.sample.data_path()\n",
    "sample_dir = sample_data_path / \"MEG\" / \"sample\"\n",
    "\n",
    "# Path to the FreeSurfer reconstructions\n",
    "subjects_dir = os.path.join(sample_data_path, \"subjects\")\n",
    "subject = \"sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformation information from coregistration\n",
    "\n",
    "Coregistration is the process of aligning head and sensor locations in a common coordinate system.\n",
    "\n",
    "This can be performed using the [`mne.gui.coregistration()`](https://mne.tools/stable/generated/mne.gui.coregistration.html) function.\n",
    "\n",
    "Run the cell below to open the coregistration GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.gui.coregistration(subject=subject, subjects_dir=subjects_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can view a transformation file from a previous coregisration for the sample data.\n",
    "\n",
    "What do the coloured dots represent?\n",
    "\n",
    "What do the blue panels represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformation file obtained by coregistration\n",
    "transformation = os.path.join(sample_dir, \"sample_audvis_raw-trans.fif\")\n",
    "\n",
    "# Load the data's information\n",
    "raw = mne.io.read_raw_fif(os.path.join(sample_dir, \"sample_audvis_raw.fif\"))\n",
    "\n",
    "# Visualise coregistration of head and sensors\n",
    "mne.viz.plot_alignment(\n",
    "    info=raw.info,\n",
    "    trans=transformation,\n",
    "    subject=subject,\n",
    "    subjects_dir=subjects_dir,\n",
    "    surfaces=\"head-dense\",\n",
    "    meg=[\"helmet\", \"sensors\"],\n",
    "    dig=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the BEM Surfaces\n",
    "\n",
    "BEM surfaces are triangulations of the interfaces between different tissues which affect the propagation of signals (e.g. inner skull surface, outer skull surface, scalp surface).\n",
    "\n",
    "Computing BEM surfaces makes use of [FreeSurfer](https://surfer.nmr.mgh.harvard.edu/), and can be performed using the [`mne.bem.make_flash_bem()`](https://mne.tools/stable/generated/mne.bem.make_flash_bem.html) or [`mne.bem.make_watershed_bem()`](https://mne.tools/stable/generated/mne.bem.make_watershed_bem.html) functions.\n",
    "\n",
    "As this takes several minutes to compute per subject, we can take advantage of the pre-existing surfaces.\n",
    "\n",
    "We plot these surfaces using the [`mne.viz.plot_bem()`](https://mne.tools/stable/generated/mne.viz.plot_bem.html) function.\n",
    "\n",
    "What do the coloured lines represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_bem(\n",
    "    subject=subject,\n",
    "    subjects_dir=subjects_dir,\n",
    "    orientation=\"coronal\",\n",
    "    slices=[50, 100, 150, 200],\n",
    "    brain_surfaces=\"white\",\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the source space\n",
    "\n",
    "The source space determines the position and orientation of candidate source locations.\n",
    "\n",
    "Source spaces can be:\n",
    "- Surface-based - source candidates are confined to a surface, e.g. the cortical surface ([`mne.setup_source_space()`](https://mne.tools/stable/generated/mne.setup_source_space.html))\n",
    "- Volumetric/discrete - source candidates are arbitrary points within an area, e.g. within the inner skull ([`mne.setup_volume_source_space()`](https://mne.tools/stable/generated/mne.setup_volume_source_space.html))\n",
    "\n",
    "Below, we create source space candidates on the cortical surface and visualise them in 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create source space candidates\n",
    "surface_sources = mne.setup_source_space(\n",
    "    subject, spacing=\"oct6\", subjects_dir=subjects_dir, add_dist=\"patch\"\n",
    ")\n",
    "\n",
    "# Visualise the candidates in 3D\n",
    "mne.viz.plot_alignment(\n",
    "    subject=subject,\n",
    "    subjects_dir=subjects_dir,\n",
    "    surfaces=\"white\",\n",
    "    coord_frame=\"mri\",\n",
    "    src=surface_sources,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating volumetric source space candidates, these can be bound to a limited area.\n",
    "\n",
    "For example, we can create candidate sources only within the brain using the BEM surface of the inner skull, which we can visualise alongside the BEM surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BEM surface for the inner skull\n",
    "inner_skull_surface = os.path.join(subjects_dir, subject, \"bem\", \"inner_skull.surf\")\n",
    "\n",
    "# Create the volumetric source candidates\n",
    "volume_sources = mne.setup_volume_source_space(\n",
    "    subject=subject, surface=inner_skull_surface, subjects_dir=subjects_dir, add_interpolator=False\n",
    ")\n",
    "\n",
    "# Visualise BEM surfaces and source space candidates (purple dots)\n",
    "mne.viz.plot_bem(\n",
    "    subject=subject,\n",
    "    subjects_dir=subjects_dir,\n",
    "    orientation=\"coronal\",\n",
    "    slices=[50, 100, 150, 200],\n",
    "    brain_surfaces=\"white\",\n",
    "    src=volume_sources,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if we did not specify a surface to bound the candidates to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing the forward model\n",
    "\n",
    "With the coregistration, BEM surfaces, and source space sorted, we can at last compute the forward model.\n",
    "\n",
    "We first load the BEM surfaces to create a BEM model using the [`mne.make_bem_model()`](https://mne.tools/stable/generated/mne.make_bem_model.html) function.\n",
    "\n",
    "We then create a BEM solution from this using the [`mne.make_bem_solution()`](https://mne.tools/stable/generated/mne.make_bem_solution.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only a single-layer BEM (just the inner skull) for speed\n",
    "conductivity = 0.3\n",
    "\n",
    "# Create the BEM model\n",
    "bem_model = mne.make_bem_model(\n",
    "    subject=subject, ico=4, conductivity=conductivity, subjects_dir=subjects_dir\n",
    ")\n",
    "\n",
    "# Use the BEM model to create the BEM solution\n",
    "bem_solution = mne.make_bem_solution(bem_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can pass the BEM solution along with our source space candidates and coregistration information to the [`mne.make_forward_solution()`](https://mne.tools/stable/generated/mne.make_forward_solution.html) function to create the forward model.\n",
    "\n",
    "Here, we only compute the model for the MEG sensors, using the surface-based (i.e. cortical) source candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the forward model\n",
    "forward = mne.make_forward_solution(\n",
    "    info=raw.info,  # data information\n",
    "    trans=transformation,  # coregistration information\n",
    "    src=surface_sources,  # surface-based source candidates\n",
    "    bem=bem_solution,  # BEM solution\n",
    "    meg=True,\n",
    "    eeg=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns an [`mne.Forward`](https://mne.tools/stable/generated/mne.Forward.html) object, which contains the forward model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leadfield matrix representing the transformation between source and sensor spaces can be extracted from the `Forward` object as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leadfield = forward[\"sol\"][\"data\"]\n",
    "print(f\"Leadfield matrix shape: {leadfield.shape} (sensors x dipoles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the number of dipoles (24,579) is 3 times greater than the number of sources (8,193).\n",
    "\n",
    "This reflects the fact that we have not specified the orientations of the sources, so the leadfield matrix is computed for each orientation in 3D space.\n",
    "\n",
    "Fixing the orientation of the sources (e.g. to a cortical orientation) can be performed using the [`mne.convert_forward_solution()`](https://mne.tools/stable/generated/mne.convert_forward_solution.html) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Inverse modelling for source localisation\n",
    "\n",
    "Now that we have a forward model, we can use this to reconstruct source activity from sensor space data.\n",
    "\n",
    "Various approaches for source reconstruction are offered in MNE:\n",
    "- Minimum norm estimation ([MNE](https://mne.tools/stable/documentation/glossary.html#term-MNE))\n",
    "- Dynamic statistical parametric mapping ([dSPM](https://mne.tools/stable/documentation/glossary.html#term-dSPM))\n",
    "- Standardised low-resolution electromagnetic tomography ([sLORETA](https://mne.tools/stable/documentation/glossary.html#term-sLORETA))\n",
    "- Exact low-resolution electromagnetic tomography ([eLORETA](https://mne.tools/stable/documentation/glossary.html#term-eLORETA))\n",
    "- Linearly constrained minimum variance ([LCMV](https://mne.tools/stable/documentation/glossary.html#term-LCMV)) [beamformer](https://mne.tools/stable/documentation/glossary.html#term-beamformer)\n",
    "- Dynamic imaging of coherent sources ([DICS](https://mne.tools/stable/documentation/glossary.html#term-DICS)) beamformer\n",
    "\n",
    "<br>\n",
    "\n",
    "Creating an inverse model requires:\n",
    "- A forward model\n",
    "- A covariance matrix\n",
    "\n",
    "<br>\n",
    "\n",
    "Below we will explore the process for creating an inverse model and applying it with the dSPM approach.\n",
    "\n",
    "We start by loading MNE's sample data and creating epochs around the left auditory stimuli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample data\n",
    "raw = mne.io.read_raw_fif(fname=os.path.join(sample_dir, \"sample_audvis_raw.fif\"))\n",
    "raw.pick(picks=[\"eeg\", \"stim\"], exclude=\"bads\")\n",
    "raw.set_eeg_reference(ref_channels=\"average\", projection=True)\n",
    "\n",
    "# Create the events array\n",
    "events = mne.find_events(raw=raw, stim_channel=\"STI 014\")\n",
    "\n",
    "# Create the epochs\n",
    "epochs = mne.Epochs(\n",
    "    raw=raw,\n",
    "    events=events,\n",
    "    event_id={\"auditory/left\": 1},  # isolate the left auditory stimuli\n",
    "    tmin=-0.2,  # start each epoch 200 ms before the stimulus\n",
    "    tmax=0.5,  # end each epoch 500 ms after the stimulus\n",
    "    baseline=(None, 0),  # baseline epochs in the window [-200, 0] ms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we average over the epochs to create ERPs in sensor space.\n",
    "\n",
    "This is the activity we will reconstruct in source space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ERPs from the epochs\n",
    "evoked = epochs.average()\n",
    "evoked.plot()\n",
    "evoked.plot_topomap(times=[-0.1, 0.0, 0.1, 0.2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are working with MNE's sample data, we can load the pre-computed forward model using [`mne.read_forward_solution()`](https://mne.tools/stable/generated/mne.read_forward_solution.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed EEG forward solution\n",
    "forward = mne.read_forward_solution(os.path.join(sample_dir, \"sample_audvis-eeg-oct-6-fwd.fif\"))\n",
    "forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to compute the covariance matrix - specifically the [covariance matrix of the noise](https://mne.tools/stable/documentation/glossary.html#term-noise-covariance) - using the [`mne.compute_covariance()`](https://mne.tools/stable/generated/mne.compute_covariance.html) function.\n",
    "\n",
    "Here, we define noise to be the baseline period preceding stimulus presentation, and as such specify that covariance should only be computed for the window [-0.2, 0] seconds.\n",
    "\n",
    "What does the covariance matrix represent, and what role does it play in the inverse model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot noise covariance\n",
    "noise_covariance = mne.compute_covariance(epochs=epochs, tmin=None, tmax=0, method=\"empirical\")\n",
    "mne.viz.plot_cov(noise_covariance, raw.info);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the forward model and covariance matrix, we can create an inverse model using the [`mne.minimum_norm.make_inverse_operator()`](https://mne.tools/stable/generated/mne.minimum_norm.make_inverse_operator.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inverse model\n",
    "inverse = mne.minimum_norm.make_inverse_operator(\n",
    "    info=evoked.info, forward=forward, noise_cov=noise_covariance\n",
    ")\n",
    "inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse model can be applied to:\n",
    "- `Evoked` objects - [`mne.minimum_norm.apply_inverse()`](https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse.html)\n",
    "- `Raw` objects - [`mne.minimum_norm.apply_inverse_raw()`](https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse_raw.html)\n",
    "- `Epochs` objects - [`mne.minimum_norm.apply_inverse_epochs()`](https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse_epochs.html)\n",
    "- `EpochsTFR` objects - [`mne.minimum_norm.apply_inverse_tfr_epochs()`](https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse_tfr_epochs.html)\n",
    "- `Covariance` objects - [`mne.minimum_norm.apply_inverse_cov()`](https://mne.tools/stable/generated/mne.minimum_norm.apply_inverse_cov.html)\n",
    "\n",
    "Here, we apply the inverse model to the ERP data using the dSPM method, which returns an [`mne.SourceEstimate`](https://mne.tools/stable/generated/mne.SourceEstimate.html) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract source activity of the ERP\n",
    "source_activity = mne.minimum_norm.apply_inverse(\n",
    "    evoked=evoked, inverse_operator=inverse, method=\"dSPM\"\n",
    ")\n",
    "source_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualise the ERPs in source space using the [`plot()`](https://mne.tools/stable/generated/mne.SourceEstimate.html#mne.SourceEstimate.plot) method.\n",
    "\n",
    "Play around with the options in the visualisation GUI to see how the [source activity](https://mne.tools/stable/documentation/glossary.html#term-source-estimate) changes over time in response to the stimuli.\n",
    "\n",
    "Does the localisation of this source activity make sense given the simulus being presented?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise source activity\n",
    "source_activity.plot(\n",
    "    subject=subject, hemi=\"rh\", subjects_dir=subjects_dir, initial_time=0.1, backend=\"pyvistaqt\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Reconstructing activity in source space is a fundamental part of many neuroscience projects involving EEG and MEG data.\n",
    "\n",
    "As you can see, there are a wide range of tools available in MNE for translating activity from sensor space to source space, which we have only briefly covered here.\n",
    "\n",
    "For more in-depth discussions of particular approaches, see the MNE tutorials linked below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "MNE forward modelling tutorials: https://mne.tools/stable/auto_tutorials/forward/index.html\n",
    "\n",
    "MNE inverse modelling tutorials: https://mne.tools/stable/auto_tutorials/inverse/index.html\n",
    "\n",
    "MNE forward modelling module: https://mne.tools/stable/api/forward.html\n",
    "\n",
    "MNE inverse modelling module: https://mne.tools/stable/api/inverse.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
