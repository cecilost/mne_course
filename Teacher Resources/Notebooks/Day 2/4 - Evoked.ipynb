{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import mne\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of event-related potentials (ERPs) - the `Evoked` class\n",
    "\n",
    "ERPs/[evoked](https://mne.tools/stable/documentation/glossary.html#term-evoked) data are another staple of many signal analysis projects.\n",
    "\n",
    "As the name implies, ERPs are changes in voltage associated with a particular event, e.g. the presentation of a stimulus, or the execution of some action.\n",
    "\n",
    "The first step in generating ERPs is to epoch the data around the event of interest, after which we generally average across the epochs to generate the final ERPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Creating `Evoked` objects from `Epochs`\n",
    "\n",
    "We start by loading the sample data, and choosing the stimulus channel from which we want to generate event markers.\n",
    "\n",
    "We additionally create a dictionary of event labels and their corresponding IDs which we want to generate epochs around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample data\n",
    "raw = mne.io.read_raw_fif(\n",
    "    os.path.join(mne.datasets.sample.data_path(), \"MEG\", \"sample\", \"sample_audvis_raw.fif\")\n",
    ")\n",
    "raw.pick(picks=[\"eeg\", \"stim\"])\n",
    "raw.del_proj()\n",
    "\n",
    "# Generate the events array\n",
    "events = mne.find_events(raw, stim_channel=\"STI 014\")\n",
    "\n",
    "# Choose the events to create epochs around\n",
    "event_id = {\n",
    "    \"auditory/left\": 1,\n",
    "    \"auditory/right\": 2,\n",
    "    \"visual/left\": 3,\n",
    "    \"visual/right\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises - Creating `Evoked` objects from `Epochs`**\n",
    "\n",
    "**Exercise:** Create an [`Epochs`](https://mne.tools/stable/generated/mne.Epochs.html) object from the data called `epochs`.\n",
    "\n",
    "Pass the `events` and `event_id` variables to the corresponding parameters to specify the events to epoch around.\n",
    "\n",
    "Using the `tmin` and `tmax` parameters, create epochs around the events in the window [-0.25, 0.75].\n",
    "\n",
    "*Hint:* Refer to the documentation for the `Epochs` class and the [Epochs notebook](../Day%201/2%20-%20Epochs.ipynb) for a reminder how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "epochs = mne.Epochs(raw=raw, events=events, event_id=event_id, tmin=-0.25, tmax=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can see that the numeric IDs of the events in the `Epochs` object have been assigned to more descriptive names provided in the `event_id` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should call the `Epochs` object created above \"epochs\"\n",
    "epochs.load_data()\n",
    "epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Averaging across the epochs to create ERPs is as simple as calling the [`average()`](https://mne.tools/stable/generated/mne.Epochs.html#mne.Epochs.average) method of the `Epochs` object.\n",
    "\n",
    "This returns an [`Evoked`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked) object.\n",
    "\n",
    "An example is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the evoked responses for the left auditory stimulus\n",
    "evoked_aud_l = epochs[\"auditory/left\"].average()\n",
    "evoked_aud_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we selected only those events corresponding to the `\"auditory/left\"` label to average across.\n",
    "\n",
    "We can visualise the ERPs using the [`plot()`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.plot) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the evoked response\n",
    "evoked_aud_l.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create ERPs for the \"auditory/right\" stimulus and visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked_aud_r = epochs[\"auditory/right\"].average()\n",
    "evoked_aud_r.plot()\n",
    "evoked_aud_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create ERPs for the \"visual/left\" stimulus and visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked_vis_l = epochs[\"visual/left\"].average()\n",
    "evoked_vis_l.plot()\n",
    "evoked_vis_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating ERPs: mean vs. median\n",
    "\n",
    "By default, calling the `average()` method on `Epochs` objects will generated `Evoked` objects using the mean of the values across the epochs.\n",
    "\n",
    "However, we can also create `Evoked` objects using the median, or even custom functions.\n",
    "\n",
    "Below, we create ERPs for the \"visual/right\" stimulus, explicitly specifying the mean to be used with the `method` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evoked responses specifying the mean method explicitly\n",
    "epochs.load_data()\n",
    "evoked_vis_r_mean = epochs[\"visual/right\"].average(method=\"mean\")\n",
    "evoked_vis_r_mean.plot()\n",
    "evoked_vis_r_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create ERPs for the \"visual/right\" stimulus using the median method, and visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked_vis_r_median = epochs[\"visual/right\"].average(method=\"median\")\n",
    "evoked_vis_r_median.plot()\n",
    "evoked_vis_r_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom functions can also be used to control how the information is combined across epochs.\n",
    "\n",
    "For example, the function below uses the data of only every other epoch and takes the mean of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def every_other_epoch_mean(epoched_data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Take the mean across every other epoch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoched_data : numpy.ndarray, shape of (epochs, channels, times)\n",
    "    - The epochs to create evoked data from.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    evoked_data : numpy.ndarray, shape of (channels, times)\n",
    "    - The evoked data as the mean across every other epoch.\n",
    "    \"\"\"\n",
    "    # Select every other epoch\n",
    "    every_other_epoch = epoched_data[::2, :, :]  # [::2] takes every other element\n",
    "\n",
    "    # Average across the remaining epochs\n",
    "    evoked_data = np.mean(every_other_epoch, axis=0)\n",
    "\n",
    "    return evoked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then simply pass this to the `method` parameter of the `average()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evoked responses using the custom method\n",
    "evoked_vis_r_custom = epochs[\"visual/right\"].average(method=every_other_epoch_mean)\n",
    "evoked_vis_r_custom.plot()\n",
    "evoked_vis_r_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling multiple event types simultaneously\n",
    "\n",
    "Multiple events types can also be selected at once for processing into `Evoked` objects.\n",
    "\n",
    "By default, averaging is performed across all selected event types, such that a single `Evoked` object is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evoked responses for the auditory stimuli\n",
    "evoked_aud = epochs[[\"auditory/left\", \"auditory/right\"]].average()\n",
    "evoked_aud.plot()\n",
    "evoked_aud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can also specify to only average across events with the same label.\n",
    "\n",
    "This behaviour is controlled with the `by_event_type` parameter of the `average()` method.\n",
    "\n",
    "`by_event_type` is by default `False`, which combines the epochs regardless of type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same behaviour as above (i.e. average across events regardless of type)\n",
    "evoked_vis = epochs[[\"visual/left\", \"visual/right\"]].average(by_event_type=False)\n",
    "evoked_vis.plot()\n",
    "evoked_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, setting `by_event_type=True` returns a list of `Evoked` objects, one for each event type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across events of the same type only\n",
    "evoked_vis = epochs[[\"visual/left\", \"visual/right\"]].average(by_event_type=True)\n",
    "for evoked in evoked_vis:\n",
    "    print(evoked)\n",
    "    evoked.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Controlling how event counts are handled\n",
    "\n",
    "You may have noticed above that the event counts for each type of event were not equal:\n",
    "- `\"auditory/left\"` stimuli occur 72 times\n",
    "- `\"auditory/right\"` stimuli occur 73 times\n",
    "- `\"visual/left\"` stimuli occur 73 times\n",
    "- `\"visual/right\"` stimuli occur 71 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample data\n",
    "raw = mne.io.read_raw_fif(\n",
    "    os.path.join(mne.datasets.sample.data_path(), \"MEG\", \"sample\", \"sample_audvis_raw.fif\")\n",
    ")\n",
    "raw.pick(picks=[\"eeg\", \"stim\"])\n",
    "raw.del_proj()\n",
    "\n",
    "# Generate the events array\n",
    "events = mne.find_events(raw, stim_channel=\"STI 014\")\n",
    "\n",
    "# Choose the events to create epochs around\n",
    "event_id = {\n",
    "    \"auditory/left\": 1,\n",
    "    \"auditory/right\": 2,\n",
    "    \"visual/left\": 3,\n",
    "    \"visual/right\": 4,\n",
    "}\n",
    "\n",
    "# Create the epochs\n",
    "epochs = mne.Epochs(raw=raw, events=events, event_id=event_id, tmin=-0.25, tmax=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equalising event counts\n",
    "\n",
    "You may wish to use an equal number of events for each type when creating ERPs, e.g. for statistical purposes.\n",
    "\n",
    "This is easily done using the [`equalize_event_counts()`](https://mne.tools/stable/generated/mne.Epochs.html#mne.Epochs.equalize_event_counts) method of the `Epochs` object (i.e. before creating the `Evoked` object).\n",
    "\n",
    "By default, the number of events will be equalised:\n",
    "- for all event types (`event_ids=None`)\n",
    "- according to those events which are temporally closest to one another (`method=\"mintime\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalise the number of epochs in each condition\n",
    "epochs.copy().equalize_event_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises - Equalising event counts**\n",
    "\n",
    "**Exercise:** Use the `event_ids` parameter of `equalize_event_counts()` to specify the auditory stimuli to have an equal number of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "epochs.copy().equalize_event_counts(event_ids=[\"auditory/left\", \"auditory/right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use the `event_ids` parameter of `equalize_event_counts()` to specify the visual stimuli to have an equal number of events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "epochs.copy().equalize_event_counts(event_ids=[\"visual/left\", \"visual/right\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use the `method` parameter of `equalize_event_counts()` to specify that event counts should be equalised by dropping the last events.\n",
    "\n",
    "How do the IDs of the dropped epochs compare to when the default `\"mintime\"` is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "epochs.copy().equalize_event_counts(method=\"truncate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining information from multiple `Evoked` objects\n",
    "\n",
    "If equalised event counts are not a concern when you compute evoked data, it is important to consider what happens when you combine this data across multiple `Evoked` objects.\n",
    "\n",
    "Data can be combined across multiple `Evoked` objects using the [`combine_evoked()`](https://mne.tools/stable/generated/mne.combine_evoked.html) function.\n",
    "\n",
    "`combine_evoked()` takes a list of `Evoked` objects, as well as a way to weight the information from these `Evoked` objects (the `weights` parameter).\n",
    "\n",
    "The weighting approaches are: `\"nave\"`; `\"equal\"`; or a list of floats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `\"nave\"` weighting\n",
    "\n",
    "With `\"nave\"`, the data from each `Evoked` object is weighted proportionally to the number of epochs that `Evoked` object was averaged across.\n",
    "\n",
    "For example, if you have one `Evoked` object from 5 auditory events and another from 15 visual events:\n",
    "- The evoked auditory data will be weighted by $\\frac{1}{4}$.\n",
    "- The evoked visual data will be weighted by $\\frac{3}{4}$.\n",
    "\n",
    "This may help to reduce noise in your evoked data, however it biases the final evoked data towards those events with a greater number, e.g. it could make it appear as if the brain's response to visual stimuli is much stronger than to auditory stimuli!\n",
    "\n",
    "An example of `\"nave\"` weighting is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ERPs for two event types\n",
    "evoked = epochs[[\"visual/right\", \"auditory/right\"]].average(by_event_type=True)\n",
    "\n",
    "# Combine ERPs by weighting according to number of events per type\n",
    "evoked_nave = mne.combine_evoked(all_evoked=evoked, weights=\"nave\")\n",
    "evoked_nave.plot()\n",
    "evoked_nave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the weightings differ slightly for each condition.\n",
    "\n",
    "This reflects the fact that there were 73 auditory stimuli and 71 visual stimuli.\n",
    "\n",
    "Dividing these counts by the total number of events (144) gives the 0.507 and 0.493 weightings for auditory and visual events, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `\"equal\"` weighting\n",
    "\n",
    "The alternative approach is to weight the epochs of each event type equally.\n",
    "\n",
    "Using the same example of 5 auditory events and 15 visual events:\n",
    "- The evoked auditory data will be weighted by $\\frac{1}{2}$.\n",
    "- The evoked visual data will be weighted by $\\frac{1}{2}$.\n",
    "\n",
    "This avoids biases arising from differences in the number of events, but may lead to noiser results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Combine the visual and auditory ERPs with an `\"equal\"` weighting.\n",
    "\n",
    "How do the results and reported weightings compare to the approach above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked_equal = mne.combine_evoked(all_evoked=evoked, weights=\"equal\")\n",
    "evoked_equal.plot()\n",
    "evoked_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom weightings\n",
    "\n",
    "Finally, custom weightings for the `Evoked` objects can also be supplied.\n",
    "\n",
    "This is done as a list of floats, with one for each `Evoked` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Provide a custom weighting for the stimuli, weighting the visual stimuli by 0.9 and the auditory stimuli by 0.1.\n",
    "\n",
    "How do the results compare to the weighting approaches above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked_custom = mne.combine_evoked(all_evoked=evoked, weights=[0.9, 0.1])\n",
    "evoked_custom.plot();\n",
    "evoked_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary of different weighting approaches\n",
    "\n",
    "Since the number of left and right visual events were so similar, weighting according to the number of events per type (`\"nave\"`) or providing equal weights (`\"equal\"`) gives very similar results.\n",
    "\n",
    "Naturally, our custom weighting skewed the evoked responses heavily towards the auditory stimuli.\n",
    "\n",
    "However, this custom weighting also mimics scenarios where there is a large difference in the number of events per condition (e.g. 90 auditory stimulus trials and 10 visual stimulus trials), where weighting according to the total number of events may have a large effect on your interpretation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Creating `Evoked` objects from arrays\n",
    "\n",
    "Like for `Raw` and `Epochs` objects, `Evoked` objects can also be created from data arrays, using the [`EvokedArray`](https://mne.tools/stable/generated/mne.EvokedArray.html) class.\n",
    "\n",
    "Below, we generate some signals as sine waves, reshape them into continuous epochs, and then average across to create 'evoked' data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation settings\n",
    "duration = 10  # seconds\n",
    "sfreq = 200  # sampling rate (Hz)\n",
    "epoch_duration = 2  # seconds\n",
    "n_epochs = duration // epoch_duration\n",
    "np.random.seed(44)  # for reproducibility\n",
    "\n",
    "# Timepoints of the simulated data\n",
    "times = np.linspace(start=0, stop=duration, num=sfreq * duration, endpoint=False)\n",
    "\n",
    "# Generate timeseries signals\n",
    "data_raw = np.array(\n",
    "    [\n",
    "        np.sin(2 * np.pi * times * 1),  # 1 Hz sine wave\n",
    "        np.sin(2 * np.pi * times * 3),  # 3 Hz sine wave\n",
    "    ]\n",
    ")\n",
    "n_channels = data_raw.shape[0]\n",
    "print(f\"Shape of timeseries data: {data_raw.shape} (channels x times)\")\n",
    "\n",
    "# Reshape into epochs\n",
    "data_epochs = np.reshape(data_raw, (n_channels, n_epochs, epoch_duration * sfreq))\n",
    "data_epochs = np.transpose(data_epochs, (1, 0, 2))\n",
    "print(f\"Shape of epoched data: {data_epochs.shape} (epochs x channels x times)\")\n",
    "\n",
    "# Average across epochs\n",
    "data_evoked = np.mean(data_epochs, axis=0)\n",
    "print(f\"Shape of evoked data: {data_evoked.shape} (channels x times)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises - Creating `Evoked` objects from arrays**\n",
    "\n",
    "**Exercise:** Using the information above, create an `Info` object for the simulated data, specifying them to be EEG channels and using the sampling frequency given above.\n",
    "\n",
    "*Hint:* use the [`create_info()`](https://mne.tools/stable/generated/mne.create_info.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "info = mne.create_info(ch_names=n_channels, sfreq=sfreq, ch_types=\"eeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use the `data_evoked` and `Info` object generated above to create an `EvokedArray` object and display its properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked = mne.EvokedArray(data=data_evoked, info=info)\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Plot the data to verify that it matches our expectations, i.e.:\n",
    "- 2 channels of a 1 and 3 Hz sine wave.\n",
    "- Duration of 2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the evoked data span from 0 to 2 seconds.\n",
    "\n",
    "The times of the data in the `EvokedArray` object can be controlled with the `tmin` parameter.\n",
    "\n",
    "Below, we explicitly set `tmin=0` (the default behaviour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evoked data from the array with explicit tmin\n",
    "info = mne.create_info(ch_names=n_channels, sfreq=sfreq, ch_types=\"eeg\")\n",
    "evoked = mne.EvokedArray(data=data_evoked, info=info, tmin=0)\n",
    "evoked.plot()\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create an `EvokedArray` object where the data spans the period [-1, 1] seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked = mne.EvokedArray(data=data_evoked, info=info, tmin=-1)\n",
    "evoked.plot()\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create an `EvokedArray` object where the data spans the period [-0.5, 1.5] seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked = mne.EvokedArray(data=data_evoked, info=info, tmin=-0.5)\n",
    "evoked.plot()\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baselining of the evoked data can be controlled when creating an `EvokedArray` object using the `baseline` parameter.\n",
    "\n",
    "Below, we explicitly set `baseline=None` (the default behaviour, i.e. no baselining)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evoked data from the array with explicit (lack of) baselining\n",
    "info = mne.create_info(ch_names=n_channels, sfreq=sfreq, ch_types=\"eeg\")\n",
    "evoked = mne.EvokedArray(data=data_evoked.copy(), info=info, baseline=None)\n",
    "evoked.plot()\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create an `EvokedArray` object baselined for the first 100 ms of data.\n",
    "\n",
    "Make sure to pass in a copy of the `data_evoked` array, like above.\n",
    "\n",
    "*Hint:* Specifying baselines for evoked data takes the same form as for epoched data, i.e. `baseline=(start, end)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked = mne.EvokedArray(data=data_evoked.copy(), info=info, baseline=(0, 0.1))\n",
    "evoked.plot()\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create an `EvokedArray` object baselined for the first 500 ms of data, where the data spans the period [-0.5, 1.5] seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked = mne.EvokedArray(data=data_evoked.copy(), info=info, tmin=-0.5, baseline=(None, 0))\n",
    "evoked.plot()\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Create an `EvokedArray` object baselined for the first 200 ms of data, where the data spans the period [-1, 1] seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE GOES HERE\n",
    "evoked = mne.EvokedArray(data=data_evoked.copy(), info=info, tmin=-1, baseline=(None, -0.8))\n",
    "evoked.plot()\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlling the times and baselining of evoked data are some of the most useful features when creating `EvokedArray` objects, however additional options exist for:\n",
    "- Providing a label for the evoked data - `comment` parameter (default `\"\"`)\n",
    "- Specifying the number of epochs which have been averaged across - `nave` parameter (default `1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evoked data from the array with explicit comment and nave\n",
    "info = mne.create_info(ch_names=n_channels, sfreq=sfreq, ch_types=\"eeg\")\n",
    "evoked = mne.EvokedArray(data=data_evoked, info=info, comment=\"example_data\", nave=n_epochs)\n",
    "evoked.plot()\n",
    "evoked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "MNE makes generating ERP data and storing it in `Evoked` objects easy, either from averaging data of `Epochs` objects, or from data arrays.\n",
    "\n",
    "Similarly to the `Raw` and `Epochs` classes, the `Evoked` class also has useful methods for:\n",
    "- picking channels - [`pick()`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.pick)\n",
    "- cropping activity by time - [`crop()`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.crop)\n",
    "- plotting topographies of activity - [`plot_topo()`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.plot_topo) and [`plot_topomap()`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.plot_topomap)\n",
    "- computing PSDs - [`compute_psd()`](https://mne.tools/stable/generated/mne.Evoked.html#mne.Evoked.compute_psd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "MNE tutorial on `Evoked` objects: https://mne.tools/stable/auto_tutorials/evoked/10_evoked_overview.html\n",
    "\n",
    "MNE tutorial on visualising `Evoked` objects: https://mne.tools/stable/auto_tutorials/evoked/20_visualize_evoked.html\n",
    "\n",
    "MNE tutorial on ERP analysis: https://mne.tools/stable/auto_tutorials/evoked/30_eeg_erp.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
